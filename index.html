<!DOCTYPE HTML>
<html lang="en">
  
<link href='https://fonts.googleapis.com/css?family=Lustria:n,i,b,bi' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Verdana:n,i,b,bi' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Helvetica:n,i,b,bi' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=sans+serif:n,i,b,bi' rel='stylesheet' type='text/css'>

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Veronica Qing Lyu 吕晴</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-170127392-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-170127392-1');
</script>
</head>



<body>
<div class="all-container">
  <div class="float-a">
    <table style="width:400px;border:0px;border-spacing:0px;border-collapse:separate;margin-left: auto; margin-right: auto;"><tbody>
        <td style="padding:0px;text-align:center">
        <tr>
          <td style="padding:2.5%;text-align:center">
            <p style="text-align:center">
              <name><strong>Veronica Qing Lyu</strong></name>
            </p>
            <a href="images/portrait.jpg"><img style="width: 80%" src="images/portrait.jpg"></a>
            <font color="grey" size="1"> <br> Photo Credit: Jieying Zhu </font>
            <p style="text-align:center">
              <email> Email: lyuqing [at] sas.upenn.edu</email>
            </p>
            <p style="text-align:center">

              <a href="https://scholar.google.com/citations?hl=en&user=RD8UGoAAAAAJ">Google Scholar</a> &nbsp|&nbsp
              <a href="https://github.com/veronica320">Github</a> &nbsp|&nbsp
              <a href="https://www.linkedin.com/in/qing-lyu-255514209/">LinkedIn</a> &nbsp|&nbsp
              <a href="cv.pdf">CV</a>
            </p>
          </td>
        </tr>
        </td>
    </tbody></table>
  </div>

  <div class="float-b">
    <table style="width:800px; max-width: 100vw; border:0px;border-spacing:0px;border-collapse:separate;"><tbody>
        <td style="padding:0px">
          <td style="padding:1%;vertical-align:top">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:20px;padding-top:70px;width:100%;vertical-align:middle">
                <heading><strong>About</strong></heading>
                <p class="light"><em>Hi!</em>  My name is Veronica Qing Lyu (吕晴). I am a third-year PhD student in Computer and Information Science at the University of Pennsylvania, affiliated with <a href="https://nlp.cis.upenn.edu">Penn NLP</a>. I am grateful to be advised by <a href="https://www.cis.upenn.edu/~ccb/">Prof. Chris Callison-Burch</a>. 
                </p>
                <p> In the previous two years, I have been working on information extraction and schema learning. My current research interests lie in the intersection of linguistics and natural language processing, especially probing language models for robustness and interpretability.
                </p>
                <p>
                  Before Penn, I was an undergrad in linguistics at the <a href="https://www.dfll.tsinghua.edu.cn/dfllen/">Department of Foreign Languages and Literatures</a> at Tsinghua University.
                </p>
              </td>
            </tbody></table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <td style="padding:20px;padding-top:10px;width:100%;vertical-align:middle">
                  <heading><strong>Research</strong></heading>
                </td>
            </tbody></table>
       
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              
              <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
                <td style="padding:20px;padding-top:0px;width:75%;vertical-align:middle">
                    <papertitle><strong>Is "<em>my favorite new movie</em>" <em>my favorite movie</em>? Probing the Understanding of Recursive Noun Phrases.</strong>
                    </papertitle> 
                  <br>
                  <strong>Qing Lyu</strong>, Hua Zheng, Daoxin Li, Li Zhang, Marianna Apidianaki, Chris Callison-Burch
                  <br>
                In Submission. [<a href="https://arxiv.org/abs/2112.08326">paper</a>][<a href="https://github.com/veronica320/Recursive-NPs">repo</a>][<a href="bib/lyu2021my.bib">bibtex</a>]
                </td>
              </tr>
              
               <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
                <td style="padding:20px;padding-top:0px;width:75%;vertical-align:middle">
                    <papertitle><strong>Visual Goal-Step Inference using wikiHow</strong>
                    </papertitle> 
                  <br>
                  Yue Yang, Artemis Panagopoulou, <strong>Qing Lyu</strong>, Li Zhang, Mark Yatskar, Chris Callison-Burch
                  <br>
                <a href="https://2021.emnlp.org/"><em>EMNLP</em> 2021.</a>; presented at the <a href="https://alvr-workshop.github.io/">2nd Workshop on Advances in Language and Vision Research</a> at <a href="https://2021.naacl.org/">NAACL 2021</a>. [<a href="https://arxiv.org/abs/2104.05845">paper</a>][<a href="bib/yang2021visual.bib">bibtex</a>]
                </td>
              </tr> 
              
              <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
                <td style="padding:20px;padding-top:0px;width:75%;vertical-align:middle">
                    <papertitle><strong>Goal-Oriented Script Construction</strong>
                    </papertitle> 
                  <br>
                  <strong>Qing Lyu</strong>*, Li Zhang*, Chris Callison-Burch
                  <br>
                  * Equal contribution.
                  <br>
                <a href="https://inlg2021.github.io/"><em>INLG</em> 2021.</a> [<a href="https://arxiv.org/abs/2107.13189">paper</a>][<a href="https://github.com/veronica320/wikihow-GOSC">repo</a>][<a href="bib/lyu-etal-2021-goal.bib">bibtex</a>]
                </td>
              </tr> 

              <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
                <td style="padding:20px;padding-top:0px;width:75%;vertical-align:middle">
                    <papertitle><strong>Zero-shot Event Extraction via Transfer Learning: Challenges and Insights</strong>
                    </papertitle> 
                  <br>
                  <strong>Qing Lyu</strong>, Hongming Zhang, Elior Sulem, Dan Roth
                  <br>
                <a href="https://2021.aclweb.org/"><em>ACL</em> 2021.</a> [<a href="https://aclanthology.org/2021.acl-short.42/">paper</a>][<a href="https://github.com/veronica320/Zeroshot-Event-Extraction">repo</a>][<a href="bib/lyu-etal-2021-zero.bib">bibtex</a>][<a href="https://underline.io/lecture/25455-zero-shot-event-extraction-via-transfer-learning-challenges-and-insights">talk</a>]
                </td>
              </tr> 


              <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
                <td style="padding:20px;padding-top:0px;width:75%;vertical-align:middle">
                    <papertitle><strong>RESIN: A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System</strong>
                    </papertitle> 
                  <br>
                  Haoyang Wen, Ying Lin, Tuan Lai, Xiaoman Pan, Sha Li, Xudong Lin, Ben Zhou, Manling Li, Haoyu Wang, Hongming Zhang, Xiaodong Yu, Alexander Dong, Zhenhailong Wang, Yi Fung, Piyush Mishra, <strong>Qing Lyu</strong>, Dídac Surís, Brian Chen, Susan Windisch Brown, Martha Palmer, Chris Callison-Burch, Carl Vondrick, Jiawei Han, Dan Roth, Shih-Fu Chang, Heng Ji
                  <br>
                <a href="https://2021.naacl.org/"><em>NAACL</em> 2021</a> demo track. [<a href="https://aclanthology.org/2021.naacl-demos.16">paper</a>][<a href="https://github.com/RESIN-KAIROS/RESIN-pipeline-public">repo</a>][<a href="bib/wen-etal-2021-resin.bib">bibtex</a>]
                </td>
              </tr> 


              <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
                <td style="padding:20px;padding-top:0px;width:75%;vertical-align:middle">
                    <papertitle><strong>Intent Detection with WikiHow</strong>
                    </papertitle> 
                  <br>
                  Li Zhang, <strong>Qing Lyu</strong>, Chris Callison-Burch
                  <br>
                <a href="http://www.aacl2020.org/"><em>AACL-IJCNLP</em> 2020.</a> [<a href="https://aclanthology.org/2020.aacl-main.35/">paper</a>][<a href="https://github.com/zharry29/wikihow-intent">repo</a>][<a href="bib/2020.aacl-main.35.bib">bibtex</a>][<a href="https://www.youtube.com/watch?v=zlw6_akYbM8">talk</a>]
                </td>
              </tr>             

              <tr onmouseout="nerf_stop()" onmouseover="nerf_start()">
                <td style="padding:20px;padding-top:0px;width:75%;vertical-align:middle">
                    <papertitle><strong>Reasoning about goals, steps, and temporal ordering with wikihow</strong>
                    </papertitle> 
                  <br>
                  Li Zhang*, <strong>Qing Lyu</strong>*, Chris Callison-Burch
                  <br>
                  * Equal contribution.
                  <br>
                <a href="https://2020.emnlp.org/"><em>EMNLP</em> 2020</a>; Spotlight presentation at the <a href="https://welmworkshop.github.io/">Workshop on Enormous Language Models (WELM)</a> at <a href="https://openreview.net/group?id=ICLR.cc/2021/Conference">ICLR 2021</a>. [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.374/">paper</a>][<a href="https://github.com/zharry29/wikihow-goal-step">repo</a>][<a href="bib/zhang-etal-2020-reasoning.bib">bibtex</a>][<a href="https://slideslive.com/38938737/reasoning-about-goals-steps-and-temporal-ordering-with-wikihow">talk</a>]
                </td>
              </tr>               

            </tbody></table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:20px;padding-top:70px;width:100%;vertical-align:middle">
                <heading><strong>Miscellaneous</strong></heading>
                <p class="light">I enjoy music and street dance in my free time. I'm also a huge fan of text adventure games!
                </p>
                <p> 
                  Check out the covers by my dance crew: <a href="https://drive.google.com/file/d/1UDObTX1kkPwGBq6CLXl8sIjoG9H2SDVq/view?usp=sharing">Lalisa</a>; <a href="https://www.youtube.com/watch?v=M0thfj07Ozg">本草纲目</a>; <a href="https://drive.google.com/file/d/1MXVvGjEAtB9OPkCCYmKnnrbHxxjAGBSP/view?usp=sharing/">将军x以父之名</a>.
                  <br>
                  My guitar cover playlist in development on <a href="https://www.youtube.com/playlist?list=PLuBKwtx74IuZm8roLnpFMG8LcHX2Z4vL6">Youtube</a>/<a href="https://space.bilibili.com/97034976/?share_source=copy_link&share_medium=iphone&bbid=Z1449E1F438A2BC6490483E0584A996F02E2&ts=1627972135">Bilibili</a>.
                  <br>
                  I wrote a <a href="https://github.com/veronica320/Werewolves-Double-Identity">role assignment tool</a> for playing <a href="https://en.wikipedia.org/wiki/The_Werewolves_of_Millers_Hollow">Werewolves</a> ("double-identity/双身份" version).
                </p>
              </td>
            </tbody></table>

          </td>
        </td>
    </tbody></table>
  </div>
</div>
</body>

</html>
